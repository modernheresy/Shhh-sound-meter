Still here! Here’s a clean version of the updated code with environment preset buttons and calibration logic:

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>shhh: Sound Meter</title>
  <style>
    body {
      font-family: sans-serif;
      background: #111;
      color: #fff;
      text-align: center;
      padding: 2em;
    }
    h1 {
      margin-bottom: 0.5em;
    }
    .presets button {
      background: #222;
      border: 1px solid #555;
      color: #fff;
      padding: 0.5em 1em;
      margin: 0.3em;
      cursor: pointer;
      border-radius: 8px;
    }
    .presets button.active {
      background: #4caf50;
    }
    .meter {
      margin-top: 2em;
      font-size: 3em;
      font-weight: bold;
      transition: color 0.2s;
    }
  </style>
</head>
<body>
  <h1>shhh: Sound Meter</h1>

  <div class="presets">
    <button data-db="40">Quiet Office</button>
    <button data-db="60">Normal Conversation</button>
    <button data-db="70">Active Classroom</button>
    <button data-db="85">Hair Dryer</button>
    <button data-db="120">Rock Concert</button>
  </div>

  <div class="meter" id="meter">-- dB</div>

  <script>
    const meter = document.getElementById('meter');
    const buttons = document.querySelectorAll('.presets button');
    let referenceDb = 60; // default

    buttons.forEach(btn => {
      btn.addEventListener('click', () => {
        buttons.forEach(b => b.classList.remove('active'));
        btn.classList.add('active');
        referenceDb = parseInt(btn.getAttribute('data-db'));
      });
    });

    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      const audioCtx = new AudioContext();
      const analyser = audioCtx.createAnalyser();
      const mic = audioCtx.createMediaStreamSource(stream);
      const processor = audioCtx.createScriptProcessor(256, 1, 1);

      analyser.fftSize = 256;
      mic.connect(analyser);
      analyser.connect(processor);
      processor.connect(audioCtx.destination);

      processor.onaudioprocess = () => {
        const data = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(data);
        let rms = Math.sqrt(data.reduce((a, b) => a + b * b, 0) / data.length);
        let db = 20 * Math.log10(rms / 255); // rough estimate
        db = Math.max(-60, db); // clamp low end
        const relativeDb = Math.round(db + referenceDb);
        meter.textContent = `${relativeDb} dB`;

        // Visual feedback color
        if (relativeDb < referenceDb + 5) {
          meter.style.color = "#4caf50"; // green
        } else if (relativeDb < referenceDb + 15) {
          meter.style.color = "#ffc107"; // yellow
        } else {
          meter.style.color = "#f44336"; // red
        }
      };
    }).catch(err => {
      meter.textContent = 'Mic access denied';
      console.error(err);
    });
  </script>
</body>
</html>

What it does:

Adds preset buttons with known dB levels.

When a button is clicked, it becomes the reference point.

The meter shows a relative dB value (estimated + reference), so it adapts to environment.

Color changes based on deviation from the reference.


Let me know when you’re ready to push this to GitHub. I can walk you through it.

